# -----------------
# Data augmentation of input data
# -----------------
# A few configurations
freq_band: &freq_band !RandomChoice [ delta, theta, alpha, beta, gamma ]
autoreject: &autoreject !RandomChoice [ true, false ]
input_length: &input_length !RandomChoice [ 5, 10, 20 ]
sfreq_multiple: &sfreq_multiple !RandomChoice [ 2, 3, 4 ]
input_ocular_state: &input_ocular_state !RandomChoice [ ec, eo ]

# Augmentations
band_pass_augmented: &band_pass_augmented !StrFormat
  string: "preprocessed_band_pass_{ocular_state}/data--band_pass-{freq_band}--input_length-{input_length}s--autoreject-{autoreject}\
    --sfreq-{sfreq_multiple}fmax"
  kwargs:
    freq_band: *freq_band
    autoreject: *autoreject
    input_length: *input_length
    sfreq_multiple: *sfreq_multiple
    ocular_state: *input_ocular_state

# The selected preprocessed version
preprocessed_version: &preprocessed_version !RandomChoice
  - *band_pass_augmented

# -----------------
# Selecting target
# -----------------
# Configurations
target_freq_band: &target_freq_band !RandomChoice [ delta, theta, alpha, beta, gamma ]
target_ocular_state: &target_ocular_state !RandomChoice [ ec, eo ]

# Targets
band_power: &band_power !StrFormat
  string: "band_power_{target_freq_band}_{target_ocular_state}"
  kwargs:
    target_freq_band: *target_freq_band
    target_ocular_state: *target_ocular_state

# The selected target
target: &target !RandomChoice
  - *band_power

# -----------------
# Datasets
# -----------------
AllDatasets: &AllDatasets
  SRM:
    num_subjects: 111
    num_time_steps: null
    pre_processed_version: *preprocessed_version
    time_series_start: null
  LEMON:
    num_subjects: 203
    num_time_steps: null
    pre_processed_version: *preprocessed_version
    time_series_start: null
  #Miltiadous:
  #  num_subjects: 88
  #  num_time_steps: null
  #  pre_processed_version: *preprocessed_version
  #  time_series_start: null
  #TDBRAIN:
  #  num_subjects: 1273
  #  num_time_steps: null
  #  pre_processed_version: *preprocessed_version
  #  time_series_start: null
  Wang:
    num_subjects: 60
    num_time_steps: null
    pre_processed_version: *preprocessed_version
    time_series_start: null

OcularStateAvailability: &OcularStateAvailability
  ec: [ SRM, LEMON, Wang ]  # Miltiadous, TDBRAIN
  eo: [ LEMON, Wang ]  # TDBRAIN

InputDatasets: &InputDatasets !SelectFromDict
  - <<: *OcularStateAvailability
  - *input_ocular_state

TargetDatasets: &TargetDatasets !SelectFromDict
  - <<: *OcularStateAvailability
  - *target_ocular_state

DatasetsNames: &DatasetsNames !ListIntersection [ *InputDatasets, *TargetDatasets ]

Datasets: &Datasets !MultiSelectFromDict
  - <<: *AllDatasets
  - *DatasetsNames

# -----------------
# Configurations for associating prediction errors with
# other variables
# -----------------
PredictionErrorAssociations: !MultiSelectFromDict
  - Miltiadous: [ mmse, age, sex, clinical_status ]
    LEMON: [ age, sex ]
    SRM: [ age, ravlt_tot, sex ]
    Wang: [ age, sex ]
    TDBRAIN: [ age, sex , indication, formal_status ]
  - *DatasetsNames

VariablesMetrics:
  age: [ pearson_r, spearman_rho ]
  mmse: [ pearson_r, spearman_rho ]
  ravlt_tot: [ pearson_r, spearman_rho ]
  clinical_status: groups_metrics
  sex: groups_metrics
  indication: groups_metrics
  formal_status: groups_metrics


# -----------------
# Configuration for subject splitting (related to the cross validation)
# -----------------
SubjectSplit:
  kwargs:
    seed: 42
  name: SplitOnDataset
SubGroups:
  sub_groups:
    dataset_name: *DatasetsNames
  verbose: true

# -----------------
# Domain discriminator
# -----------------
# Using an FC module
ExponentialDecayFC: &ExponentialDecayFC
  proposed_depth: !UniformInt [ 0, 5 ]
  first_layer_multiple: !Uniform [ 0.5, 2 ]
  exponential_decrease: !RandomChoice [ 2, 3 ]
  in_features: UNDETERMINED  # Need to 'ask' the DL architecture
  num_classes: &num_discriminator_classes !Sum [ !MappingLength [ *Datasets ], -1 ]
  activation_function: !RandomChoice
    - name: relu
      kwargs: {}
    - name: elu
      kwargs: {alpha: !Uniform [ 0.2, 1.8 ]}

FCModule: &FCModule !RandomChoice
  - method: exponential_decay
    kwargs: *ExponentialDecayFC

# Selecting domain discriminator
_discriminator: &_discriminator !RandomChoice
  - null
  - name: FCModule
    kwargs: *FCModule
DomainDiscriminator:
  discriminator: &discriminator !IfZeroElse  # No need for a domain discriminator if only one dataset for training
    condition: !Sum [ *num_discriminator_classes, -1 ]
    true: null
    false: *_discriminator
  training:
    Loss:
      loss: CrossEntropyLoss
      loss_kwargs:
        reduction: mean
      weighter: null
      weighter_kwargs: { }
    metrics: !Tuple [ acc, ce_loss ]
    lambda: !LogUniform [10, -6, -1]

# -----------------
# Training configurations
# -----------------
Scalers:
  target:
    kwargs: {}
    name: ZNormalisation
Training:
  batch_size: 128
  num_epochs: 50
  verbose: true
  verbose_variables: false
  continuous_testing: true
  metrics: regression
  method: !IfIsNoneElse {condition: *discriminator, true: downstream_training, false: domain_discriminator_training}
  prediction_activation_function: null
  main_metric: pearson_r  # todo: this should not be required
  learning_rate: !LogUniform [10, -5, -3]
  beta_1: !Uniform [0.8, 1.0]
  beta_2: !Uniform [0.9, 1.0]
  eps: !LogUniform [10, -10, -6]
  ValSplit:  # todo: a little weird to have it in Training config?
    name: DatasetBalancedTrainValSplit
    kwargs:
      val_split: 0.2
  target: *target
  Loss:
    loss: !RandomChoice [ MSELoss, L1Loss ]
    loss_kwargs:
      reduction: UNDETERMINED
    weighter: !RandomChoice [ null, SamplePowerWeighter ]
    weighter_kwargs:
      weight_power: !Uniform [0, 1]

# -----------------
# DL architectures
# -----------------
num_time_steps: &num_time_steps !SelectFromDict
  - delta: !MultiplierInt [ *input_length, *sfreq_multiple, 4 ]
    theta: !MultiplierInt [ *input_length, *sfreq_multiple, 8 ]
    alpha: !MultiplierInt [ *input_length, *sfreq_multiple, 12 ]
    beta: !MultiplierInt [ *input_length, *sfreq_multiple, 30 ]
    gamma: !MultiplierInt [ *input_length, *sfreq_multiple, 45 ]
  - *freq_band

# Inception network
InceptionNetwork: &InceptionNetwork
  num_classes: 1
  cnn_units: !LogUniformInt [2, 3, 6]
  depth: !NLogUniformInt [3, 3, 0, 3]

# ShallowFBCSPNet
_n_filters: &_n_filters !UniformInt [30, 51]
ShallowFBCSPNetMTS: &ShallowFBCSPNetMTS
  num_classes: 1
  num_time_steps: *num_time_steps
  n_filters_time: *_n_filters
  n_filters_spat: *_n_filters
  filter_time_length: !UniformInt [15, 36]
  pool_time_stride: &pool_time_stride !UniformInt [10, 21]
  pool_time_length: !MultiplierInt [ 5, *pool_time_stride ]
  drop_prob: !Uniform [0, 0.5]

# Deep4Net
_n_first_filters: &_n_first_filters !UniformInt [15, 36]
_filter_length: &_filter_length !UniformInt [5, 16]
Deep4NetMTS: &Deep4NetMTS
  num_classes: 1
  num_time_steps: *num_time_steps
  n_filters_time: *_n_first_filters
  n_filters_spat: *_n_first_filters
  n_filters_2: !MultiplierInt [ 2, *_n_first_filters ]
  n_filters_3: !MultiplierInt [ 4, *_n_first_filters ]
  n_filters_4: !MultiplierInt [ 8, *_n_first_filters ]
  filter_time_length: *_filter_length
  filter_length_2: *_filter_length
  filter_length_3: *_filter_length
  filter_length_4: *_filter_length
  drop_prob: !Uniform [0, 0.5]

# Selected DL architecture
DLArchitecture: !RandomChoice
  - model: InceptionNetwork
    kwargs: *InceptionNetwork
  - model: ShallowFBCSPNetMTS
    kwargs: *ShallowFBCSPNetMTS
  - model: Deep4NetMTS
    kwargs: *Deep4NetMTS

# -----------------
# Varied numbers of channels
# -----------------
# Region based pooling. The logic for creating all hyperparameters are a little too much for a .yml file, so these are
# the hyperparameters of the sampling of RBP

# Pooling modules
num_kernels: &num_kernels !TypeLogUniformInt [ 10, 2, 3 ]
max_receptive_field: &max_receptive_field !TypeLogUniformInt [ 10, 2, 3 ]  # todo: use seconds as unit instead

MultiMSMean: &MultiMSMean
  pooling_method: MultiMSMean
  pooling_method_kwargs: !GetDict {}

MultiMSSharedRocket: &MultiMSSharedRocket
  pooling_method: MultiMSSharedRocket
  pooling_method_kwargs: !GetDict { num_kernels: *num_kernels, max_receptive_field: *max_receptive_field }

MultiMSSharedRocketHeadRegion: &MultiMSSharedRocketHeadRegion
  pooling_method: MultiMSSharedRocketHeadRegion
  pooling_method_kwargs: !GetDict
    num_kernels: *num_kernels
    max_receptive_field: *max_receptive_field
    latent_search_features: !TypeLogUniformInt [ 2, 3, 7 ]
    share_search_receiver_modules: !TypeRandomChoice [ true, false ]
    bias: false

# Montage splits
CentroidPolygons: &CentroidPolygons
  name: CentroidPolygons
  kwargs: !GetDict
    channel_positions: [ Miltiadous ]
    min_nodes: !TypeUniformInt [ 1, 6 ]
    k: !TypeRandomChoice
      - [ 2, 2, 2, 2, 2, 2, 2 ]
      - [ 3, 3, 3, 3, 3, 3, 3, 3 ]
      - [ 2, 3, 2, 3, 2, 3, 2, 3, 2 ]
      - [ 4, 3, 2, 3, 4, 3, 2, 3, 4 ]

# CMMN
NoCMMN: &NoCMMN
  cmmn_kwargs: null
  use_cmmn_layer: false

_kernel_size_multiple: &kernel_size_multiple !Uniform [0.5, 4]
_kernel_size: &cmmn_kernel_size !SelectFromDict
  - delta: !MultiplierInt [ *kernel_size_multiple, 4 ]
    theta: !MultiplierInt [ *kernel_size_multiple, 8 ]
    alpha: !MultiplierInt [ *kernel_size_multiple, 12 ]
    beta: !MultiplierInt [ *kernel_size_multiple, 30 ]
    gamma: !MultiplierInt [ *kernel_size_multiple,45 ]
  - *freq_band
CMMN: &CMMN
  cmmn_kwargs: !GetDict { kernel_size: *cmmn_kernel_size }
  use_cmmn_layer: true

_num_montage_splits: &num_montage_splits !LogUniformInt [2, 0, 3]
_share_all_pooling_modules: &share_all_pooling_modules !RandomChoice [ true, false ]
_num_pooling_modules: &num_pooling_modules !IfElse { condition: *share_all_pooling_modules, true: 1, false: !UniformInt [ 1, !Sum [ *num_montage_splits, 1 ] ] }
_partitions: &partitions !CreatePartitionSizes [ *num_montage_splits, *num_pooling_modules ]
RegionBasedPooling: &RegionBasedPooling
  normalise_region_representations: !RandomChoice [ true, false ]
  RBPDesigns: !SampleRBPDesigns
    partitions: *partitions
    designs:
      num_designs: 1
      pooling_type: multi_cs  # this shouldn't be necessary
      pooling_module: !TypeRandomChoice [ *MultiMSMean, *MultiMSSharedRocket, *MultiMSSharedRocketHeadRegion ]
      montage_splits: !TypeRandomChoice [ *CentroidPolygons ]
      cmmn: !RandomChoice [ *NoCMMN, *CMMN ]

# Interpolation
Interpolation: &Interpolation
  main_channel_system: !RandomChoiceFromList [ *DatasetsNames ]
  method: !RandomChoice [ MNE, spline ]

# Selecting method for handling varied electrode configurations
Varied Numbers of Channels: !RandomChoice
  - name: RegionBasedPooling
    kwargs: *RegionBasedPooling
  #- name: Interpolation
  #  kwargs: *Interpolation


Varied Numbers of Channrels:
  kwargs:
    RBPDesigns:
      RBPDesign0:
        cmmn_kwargs: null
        num_designs: 1
        pooling_methods: MultiMSSharedRocketHeadRegion
        pooling_methods_kwargs:
          bias: false
          latent_search_features: 23
          max_receptive_field: 141
          num_kernels: 321
          share_search_receiver_modules: true
        pooling_type: multi_cs
        split_methods:
        - CentroidPolygons
        - CentroidPolygons
        - CentroidPolygons
        - CentroidPolygons
        split_methods_kwargs:
        - channel_positions: &id001
          - Miltiadous
          k: &id002
          - 4
          - 3
          - 2
          - 3
          - 4
          - 3
          - 2
          - 3
          - 4
          min_nodes: 4
        - channel_positions: *id001
          k:
          - 2
          - 2
          - 2
          - 2
          - 2
          - 2
          - 2
          min_nodes: 3
        - channel_positions: *id001
          k: *id002
          min_nodes: 1
        - channel_positions: *id001
          k: *id002
          min_nodes: 1
        use_cmmn_layer: false
    normalise_region_representations: true
  name: RegionBasedPooling
